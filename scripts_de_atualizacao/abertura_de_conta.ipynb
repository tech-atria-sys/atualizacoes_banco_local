{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "from pandas.tseries.offsets import BDay\n",
    "\n",
    "# Caminhos dos seus módulos customizados\n",
    "sys.path.insert(0, r'C:\\Scripts\\modules\\database')\n",
    "sys.path.insert(0, r'C:\\Scripts\\modules\\parameters')\n",
    "\n",
    "from connection import Connect\n",
    "from bases import Bases\n",
    "from parametros import Parametros\n",
    "\n",
    "diretorio_base = r\"C:\\Scripts\\relatórios\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "pastas_dias = []\n",
    "\n",
    "# Coleta as pastas diretamente na raiz de relatórios (pulando a pasta mês)\n",
    "for dia in next(os.walk(r\"C:\\\\Scripts\\\\relatórios\"))[1]:\n",
    "    try:\n",
    "        datetime.strptime(dia, \"%d-%m-%Y\")\n",
    "        pastas_dias.append({\"dia\": dia})\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n",
    "# Ordena igual ao original\n",
    "pastas_dias.sort(key = lambda date: datetime.strptime(date[\"dia\"], \"%d-%m-%Y\"))\n",
    "\n",
    "# Lista para armazenar os DataFrames de cada dia\n",
    "lista_entrada_saida = []\n",
    "\n",
    "for presente in pastas_dias:\n",
    "    dia_str = presente['dia']\n",
    "    diretorio_pastas_presente = os.path.join(diretorio_base, dia_str)\n",
    "    \n",
    "    try:\n",
    "        subpastas = os.listdir(diretorio_pastas_presente)\n",
    "        if not subpastas:\n",
    "            continue\n",
    "            \n",
    "        base_hoje = subpastas[0]\n",
    "        caminho_final = os.path.join(diretorio_pastas_presente, base_hoje, \"base_btg.xlsx\")\n",
    "        \n",
    "        # Tenta ler o arquivo\n",
    "        try:\n",
    "            df = pd.read_excel(caminho_final, header=2)\n",
    "            if 'Conta' not in df.columns:\n",
    "                df = pd.read_excel(caminho_final)\n",
    "        except:\n",
    "            df = pd.read_excel(caminho_final)\n",
    "\n",
    "        # Padroniza colunas (Remove \" (R$)\" e espaços)\n",
    "        df.columns = [str(c).replace(\" (R$)\", \"\").strip() for c in df.columns]\n",
    "\n",
    "        # Mostra o dia e as colunas originais encontradas antes de renomear\n",
    "        print(f\"--- Processando dia: {dia_str} ---\")\n",
    "        print(f\"Colunas encontradas: {list(df.columns)}\")\n",
    "\n",
    "        # Tratamento da coluna de abertura\n",
    "        mapeamento = {'Data de Abertura da Conta': 'Data de Abertura', 'Data Vínculo Assessor': 'Data Vínculo'}\n",
    "        df.rename(columns=mapeamento, inplace=True)\n",
    "\n",
    "        # Seleção das colunas\n",
    "        colunas_alvo = ['Conta', 'Assessor', 'Data de Abertura', 'Data Vínculo', 'Faixa Cliente', 'PL Total']\n",
    "        colunas_existentes = [c for c in colunas_alvo if c in df.columns]\n",
    "        \n",
    "        # DEBUG: Confirma o que foi selecionado após o tratamento\n",
    "        print(f\"Colunas selecionadas: {colunas_existentes}\\n\")\n",
    "\n",
    "        df_final = df[colunas_existentes].copy()\n",
    "        \n",
    "        if 'Conta' in df_final.columns:\n",
    "            df_final['Conta'] = df_final['Conta'].astype(str)\n",
    "\n",
    "        lista_entrada_saida.append(df_final)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"!!! ERRO no dia {dia_str}: {e}\\n\")\n",
    "\n",
    "historico_abertura = pd.concat(lista_entrada_saida, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_entrada_saida = []\n",
    "diretorio_base = r\"C:\\Scripts\\relatórios\"\n",
    "\n",
    "pastas_processadas = 0\n",
    "datas_lidas = []\n",
    "\n",
    "print(\"Iniciando processamento...\\n\")\n",
    "\n",
    "for presente in pastas_dias:\n",
    "    dia_str = presente['dia']\n",
    "    caminho_dia = os.path.join(diretorio_base, dia_str)\n",
    "    \n",
    "    try:\n",
    "        subpastas = os.listdir(caminho_dia)\n",
    "        if not subpastas:\n",
    "            continue\n",
    "            \n",
    "        pasta_hora = subpastas[0]\n",
    "        caminho_arquivo = os.path.join(caminho_dia, pasta_hora, \"base_btg.xlsx\")\n",
    "\n",
    "        # Leitura do Excel\n",
    "        try:\n",
    "            df = pd.read_excel(caminho_arquivo, header=2)\n",
    "            if 'Conta' not in df.columns:\n",
    "                df = pd.read_excel(caminho_arquivo)\n",
    "        except:\n",
    "            df = pd.read_excel(caminho_arquivo)\n",
    "\n",
    "        # Padronização e Mapeamento\n",
    "        df.columns = [str(c).replace(\" (R$)\", \"\").strip() for c in df.columns]\n",
    "        \n",
    "        mapeamento = {\n",
    "            'Data de Abertura da Conta': 'Data de Abertura',\n",
    "            'Data de Abertura do Assessor': 'Data de Abertura',\n",
    "            'Data Vínculo Assessor': 'Data Vínculo'\n",
    "        }\n",
    "        df.rename(columns=mapeamento, inplace=True)\n",
    "\n",
    "        colunas_alvo = ['Conta', 'Assessor', 'Data de Abertura', 'Data Vínculo', 'Faixa Cliente', 'PL Total']\n",
    "        colunas_final = [c for c in colunas_alvo if c in df.columns]\n",
    "        \n",
    "        base_atual = df[colunas_final].copy()\n",
    "        if 'Conta' in base_atual.columns:\n",
    "            base_atual['Conta'] = base_atual['Conta'].astype(str)\n",
    "\n",
    "        lista_entrada_saida.append(base_atual)\n",
    "        \n",
    "        # Atualiza contadores para o Debug\n",
    "        pastas_processadas += 1\n",
    "        datas_lidas.append(datetime.strptime(dia_str, \"%d-%m-%Y\"))\n",
    "\n",
    "        # Log individual simplificado para não poluir o console\n",
    "        print(f\"[OK] {dia_str} | Colunas: {len(colunas_final)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERRO] Dia {dia_str}: {e}\")\n",
    "\n",
    "# --- RESUMO DO DEBUG ---\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"      RESUMO DO PROCESSO\")\n",
    "print(\"=\"*30)\n",
    "if datas_lidas:\n",
    "    print(f\"Total de pastas lidas: {pastas_processadas}\")\n",
    "    print(f\"Data inicial: {min(datas_lidas).strftime('%d/%m/%Y')}\")\n",
    "    print(f\"Data final:   {max(datas_lidas).strftime('%d/%m/%Y')}\")\n",
    "    print(f\"Última pasta lida: {dia_str}\")\n",
    "else:\n",
    "    print(\"Nenhuma pasta foi processada.\")\n",
    "print(\"=\"*30 + \"\\n\")\n",
    "\n",
    "if lista_entrada_saida:\n",
    "    historico_abertura = pd.concat(lista_entrada_saida, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historico_abertura = pd.concat(lista_entrada_saida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historico_abertura = \\\n",
    "    historico_abertura[\n",
    "        ~((historico_abertura['Assessor'] == 'Gabriel Rodrigues') &\n",
    "        (historico_abertura['Data Vínculo'] >= \"2024-02-01\") &\n",
    "        (historico_abertura['Data Vínculo'] <= \"2024-03-01\"))\n",
    "    ]\n",
    "    \n",
    "historico_abertura = \\\n",
    "    historico_abertura[\n",
    "        ~((historico_abertura['Assessor'] == 'Vinicius Servino Vargas') &\n",
    "        (historico_abertura['Data Vínculo'] == \"2024-02-08\"))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = Connect.connect_techdb()\n",
    "entradas_saidas_consolidado = Connect.import_table(conn, 'Entradas_e_saidas_consolidado')\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entradas_saidas_consolidado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sairam_entraram = historico_abertura.merge(entradas_saidas_consolidado[entradas_saidas_consolidado['Situação'] == 'Saiu'][['Conta', 'Mês de entrada/saída']], on='Conta', how='left')\n",
    "sairam_entraram = \\\n",
    "    sairam_entraram[\n",
    "        (sairam_entraram['Mês de entrada/saída'] < sairam_entraram['Data Vínculo'])\n",
    "    ]\n",
    "sairam_entraram.drop(\"Mês de entrada/saída\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historico_abertura = historico_abertura[~historico_abertura['Conta'].isin(sairam_entraram['Conta'])]\n",
    "historico_abertura = pd.concat([historico_abertura, sairam_entraram], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historico_abertura.drop_duplicates(subset=[\"Conta\"], keep='first', inplace=True)\n",
    "historico_abertura.rename(columns={\"Faixa Cliente\":\"Faixa Cliente Abertura\", \"PL Total\":\"PL Abertura\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primeiro_vinculo = historico_abertura[['Assessor', 'Conta', 'Data Vínculo', 'Faixa Cliente Abertura', 'PL Abertura']]\n",
    "#primeiro_vinculo.rename(columns={\"Data Vínculo\":\"Primeiro Vínculo\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conexao = Connect.connect_techdb()\n",
    "basebtg = Connect.import_table(conexao, \"base_btg\")\n",
    "conexao.close()\n",
    "\n",
    "# 1. Padroniza os nomes das colunas (remove espaços extras que o banco pode trazer)\n",
    "basebtg.columns = basebtg.columns.str.strip()\n",
    "\n",
    "# 2. Mapeia todas as versões possíveis da coluna de abertura\n",
    "# Se o banco trouxer o nome novo, ele converte corretamente\n",
    "mapeamento_abertura = {\n",
    "    'Data de Abertura do Assessor': 'Data de Abertura',\n",
    "    'Data de Abertura da Conta': 'Data de Abertura'\n",
    "}\n",
    "basebtg.rename(columns=mapeamento_abertura, inplace=True)\n",
    "\n",
    "# 3. Faz o merge apenas com as colunas que agora temos certeza que existem\n",
    "try:\n",
    "    base_vinculos = primeiro_vinculo.merge(\n",
    "        basebtg[['Conta', 'Data de Abertura']], \n",
    "        on='Conta', \n",
    "        how='left'\n",
    "    )\n",
    "    base_vinculos = base_vinculos.dropna(subset=\"Data Vínculo\")\n",
    "    print(\"Merge realizado com sucesso usando a coluna: Data de Abertura\" )\n",
    "except KeyError:\n",
    "    # Caso o banco tenha um nome totalmente diferente, esse debug te avisará qual é\n",
    "    print(f\"Erro: Não achei a coluna de abertura. Colunas no banco são: {basebtg.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vinculos = primeiro_vinculo.merge(basebtg[['Conta', 'Data de Abertura']], on='Conta', how='left')\n",
    "base_vinculos = base_vinculos.dropna(subset=\"Data Vínculo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filtrada = base_vinculos.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origem = pd.read_excel(r'C:\\Scripts\\backups_atria\\historico_relatorios\\historico_nnm\\NNM Válido Potenza - Parcial 07.02.2023.xlsx')\n",
    "origem = origem[['Conta', 'Origem da Conta']]\n",
    "origem['Conta'] = origem['Conta'].astype(str)\n",
    "origem.drop_duplicates(subset=\"Conta\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filtrada = base_filtrada.merge(origem, on='Conta', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filtrada = base_filtrada[[\n",
    "    'Conta', 'Assessor','Data de Abertura', 'Data Vínculo', \n",
    "    'Faixa Cliente Abertura', 'Origem da Conta', 'PL Abertura'\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filtrada['Tipo'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filtrada.loc[\n",
    "    (base_filtrada['Data de Abertura'] == base_filtrada['Data Vínculo']),\n",
    "    \"Tipo\"\n",
    "] = \"Abertura\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filtrada.loc[\n",
    "    (base_filtrada['Data Vínculo'] != base_filtrada['Data de Abertura']),\n",
    "    \"Tipo\"\n",
    "] = \"Migração\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filtrada = base_filtrada[~base_filtrada['Data de Abertura'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filtrada['Mes Abertura'] = [data.strftime(\"%Y-%m\") for data in base_filtrada['Data de Abertura']]\n",
    "base_filtrada['Mes Vinculo'] = [data.strftime(\"%Y-%m\") for data in base_filtrada['Data Vínculo']]\n",
    "base_filtrada['PL Abertura'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filtrada = base_filtrada[\n",
    "                    (base_filtrada['Tipo'] != \"Migração Interna\") &\n",
    "                    (base_filtrada['Tipo'] != \"\")\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filtrada = pd.merge(base_filtrada, basebtg[['Conta', 'PL Total']], on='Conta', how='left')\n",
    "base_filtrada['PL Total'].fillna(0, inplace=True)\n",
    "base_filtrada.rename(columns={\"PL Total\":\"PL Atual\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conexao = Connect.connect_techdb()\n",
    "pl_historico = Connect.import_table(conexao, \"PL Base\")\n",
    "conexao.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contas_pl = base_filtrada['Conta']\n",
    "\n",
    "for conta in contas_pl:\n",
    "    try:\n",
    "        if len(pl_historico[(pl_historico['CONTA'] == conta)].sort_values(\"Mês\")) > 1:\n",
    "            pl_mes_abertura = pl_historico[(pl_historico['CONTA'] == conta)].sort_values(\"Mês\").iloc[1,:]['PL']\n",
    "            base_filtrada.loc[(base_filtrada['Conta'] == conta), 'PL Abertura'] = pl_mes_abertura\n",
    "        else:\n",
    "            pl_mes_abertura = pl_historico[(pl_historico['CONTA'] == conta)].sort_values(\"Mês\")['PL'].values[0]\n",
    "            base_filtrada.loc[(base_filtrada['Conta'] == conta), 'PL Abertura'] = pl_mes_abertura\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filtrada.loc[base_filtrada['PL Abertura'] < 300000, \"Faixa Cliente Abertura\"] = \"< 300k\"\n",
    "base_filtrada.loc[(base_filtrada['PL Abertura'] >= 300000) & (base_filtrada['PL Abertura'] < 1000000), \"Faixa Cliente Abertura\"] = \"> 300k e < 1mm\"\n",
    "base_filtrada.loc[(base_filtrada['PL Abertura'] >= 1000000) & (base_filtrada['PL Abertura'] < 5000000), \"Faixa Cliente Abertura\"] = \"> 1mm e < 5mm\"\n",
    "base_filtrada.loc[base_filtrada['PL Abertura'] > 5000000, \"Faixa Cliente Abertura\"] = \"> 5mm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filtrada.loc[base_filtrada['PL Atual'] < 300000, \"Faixa Cliente Atual\"] = \"< 300k\"\n",
    "base_filtrada.loc[(base_filtrada['PL Atual'] >= 300000) & (base_filtrada['PL Atual'] < 1000000), \"Faixa Cliente Atual\"] = \"> 300k e < 1mm\"\n",
    "base_filtrada.loc[(base_filtrada['PL Atual'] >= 1000000) & (base_filtrada['PL Atual'] < 5000000), \"Faixa Cliente Atual\"] = \"> 1mm e < 5mm\"\n",
    "base_filtrada.loc[base_filtrada['PL Atual'] > 5000000, \"Faixa Cliente Atual\"] = \"> 5mm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filtrada.loc[base_filtrada['PL Atual'] < 1000000, \"Faixa Cliente Performance\"] = \"< 1MM\"\n",
    "base_filtrada.loc[base_filtrada['PL Atual'] >= 1000000, \"Faixa Cliente Performance\"] = \"> 1MM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filtrada.loc[base_filtrada['Assessor'] == \"Rodrigo de Mello D?Elia\", \"Assessor\"] = \"Rodrigo de Mello D’Elia\"\n",
    "base_filtrada.loc[base_filtrada['Assessor'] == \"Rodrigo de Mello DElia\", \"Assessor\"] = \"Rodrigo de Mello D’Elia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filtrada['Assessor'] = [nome.upper() for nome in base_filtrada['Assessor']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo_potenza = base_filtrada[['Conta', 'Data Vínculo', 'Assessor']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo_potenza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conexao = Connect.connect_techdb()\n",
    "tempo_potenza.to_sql(\"primeiro_vinculo\", \n",
    "                     con=conexao, \n",
    "                     index=False, \n",
    "                     if_exists='replace',\n",
    "                     schema='principal')\n",
    "conexao.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filtrada = base_filtrada[\n",
    "        (base_filtrada['Data Vínculo'] >= \"2022-01-01\") |\n",
    "        (base_filtrada['Data de Abertura'] >= \"2022-01-01\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomes_clientes = pd.read_excel(r\"C:\\\\Scripts\\\\nomes_clientes\\\\Nomes_Clientes2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filtrada = base_filtrada.merge(nomes_clientes, on='Conta', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filtrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filtrada.loc[base_filtrada['Conta'] == '590732', \"Assessor\"] = \"JOSE AUGUSTO ALVES DE PAULA FILHO\"\n",
    "base_filtrada.loc[base_filtrada['Conta'] == '299305', \"Assessor\"] = \"JOSE AUGUSTO ALVES DE PAULA FILHO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Ordena pela Data Vínculo do mais recente para o mais antigo\n",
    "base_recente = base_filtrada.sort_values(by='Data Vínculo', ascending=False)\n",
    "\n",
    "print(f\"--- Top 10 registros com as datas de vínculo mais recentes ---\")\n",
    "print(f\"Total de linhas na base: {len(base_recente)}\")\n",
    "\n",
    "# Mostra as colunas principais para facilitar a conferência\n",
    "display(base_recente[['Conta', 'Assessor', 'Data de Abertura', 'Data Vínculo', 'Tipo', 'PL Atual']].head(10))\n",
    "\n",
    "# %%\n",
    "# DEBUG: Verificando se existem datas nulas que podem estar fugindo da ordenação\n",
    "nulos = base_recente['Data Vínculo'].isna().sum()\n",
    "if nulos > 0:\n",
    "    print(f\"Atenção: Existem {nulos} linhas com Data Vínculo vazia.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conexao = Connect.connect_techdb()\n",
    "base_filtrada.to_sql(\"abertura_de_conta_base\", \n",
    "                     con=conexao, \n",
    "                     index=False, \n",
    "                     if_exists='replace',\n",
    "                     schema='principal')\n",
    "conexao.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abertura = base_filtrada[base_filtrada['Tipo'] == \"Abertura\"]\n",
    "abertura = abertura.groupby([\"Assessor\", \"Mes Abertura\", \"Faixa Cliente Abertura\", \"Faixa Cliente Atual\", \"Faixa Cliente Performance\"])['Data de Abertura'].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vinculo = base_filtrada[base_filtrada['Tipo'] == \"Migração\"]\n",
    "vinculo = vinculo.groupby([\"Assessor\", \"Mes Vinculo\", \"Faixa Cliente Abertura\", \"Faixa Cliente Atual\", \"Faixa Cliente Performance\"])['Data Vínculo'].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abertura.rename(columns={\"Mes Abertura\":\"Mes\", \"Data de Abertura\":\"Contas Abertas\"}, inplace=True)\n",
    "vinculo.rename(columns={\"Mes Vinculo\":\"Mes\", \"Data Vínculo\":\"Contas Vinculadas\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = abertura.merge(vinculo, on=['Assessor', 'Mes', 'Faixa Cliente Abertura', 'Faixa Cliente Atual', 'Faixa Cliente Performance'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Encontra a data mínima e máxima dentro da sua base tratada\n",
    "# Usamos 'pd.to_datetime' para garantir que não dê erro de tipo\n",
    "data_min = min(pd.to_datetime(base_filtrada['Data de Abertura']).min(), pd.to_datetime(base_filtrada['Data Vínculo']).min())\n",
    "data_max = max(pd.to_datetime(base_filtrada['Data de Abertura']).max(), pd.to_datetime(base_filtrada['Data Vínculo']).max())\n",
    "\n",
    "# 2. Cria a lista de datas mensais (frequência 'MS' = Month Start)\n",
    "datas = pd.date_range(start=data_min, end=data_max, freq='MS')\n",
    "\n",
    "print(f\"Gerando calendário de {data_min.strftime('%m/%Y')} até {data_max.strftime('%m/%Y')}\")\n",
    "\n",
    "# --- SEU CÓDIGO ORIGINAL CONTINUA AQUI ---\n",
    "\n",
    "df_datas_list = []\n",
    "\n",
    "# Pegamos os valores únicos de cada coluna para criar a matriz completa\n",
    "lista_assessores = df['Assessor'].unique() if 'Assessor' in df.columns else []\n",
    "lista_faixas_abertura = df['Faixa Cliente Abertura'].unique() if 'Faixa Cliente Abertura' in df.columns else []\n",
    "lista_faixas_atual = df['Faixa Cliente Atual'].unique() if 'Faixa Cliente Atual' in df.columns else []\n",
    "\n",
    "# Agora o 'datas' existe e o loop vai funcionar\n",
    "for data in datas:\n",
    "    mes_str = data.strftime(\"%Y-%m\")\n",
    "    for assessor in lista_assessores:\n",
    "        for faixa_abertura in lista_faixas_abertura:\n",
    "            for faixa_atual in lista_faixas_atual:\n",
    "                \n",
    "                df_datas_list.append({\n",
    "                    \"Mes\": mes_str,\n",
    "                    \"Assessor\": assessor,\n",
    "                    \"Faixa Cliente Abertura\": faixa_abertura,\n",
    "                    \"Faixa Cliente Atual\": faixa_atual\n",
    "                })\n",
    "\n",
    "df_datas = pd.DataFrame(df_datas_list)\n",
    "\n",
    "print(f\"✅ Sucesso! Geradas {len(df_datas)} linhas de base para o histórico.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "df_datas_list = []\n",
    "\n",
    "# Pegamos os valores únicos de cada coluna para criar a matriz completa\n",
    "# Usamos .unique() e tratamos caso a coluna não exista para o script não parar\n",
    "lista_assessores = df['Assessor'].unique() if 'Assessor' in df.columns else []\n",
    "lista_faixas_abertura = df['Faixa Cliente Abertura'].unique() if 'Faixa Cliente Abertura' in df.columns else []\n",
    "lista_faixas_atual = df['Faixa Cliente Atual'].unique() if 'Faixa Cliente Atual' in df.columns else []\n",
    "\n",
    "for data in datas:\n",
    "    mes_str = data.strftime(\"%Y-%m\")\n",
    "    for assessor in lista_assessores:\n",
    "        for faixa_abertura in lista_faixas_abertura:\n",
    "            for faixa_atual in lista_faixas_atual:\n",
    "                # Criamos um dicionário simples para cada linha\n",
    "                df_datas_list.append({\n",
    "                    \"Mes\": mes_str,\n",
    "                    \"Assessor\": assessor,\n",
    "                    \"Faixa Cliente Abertura\": faixa_abertura,\n",
    "                    \"Faixa Cliente Atual\": faixa_atual\n",
    "                })\n",
    "\n",
    "# Transforma a lista de dicionários em DataFrame de uma vez só\n",
    "# Isso substitui o pd.concat(dfs) e já cria a coluna 'Mes'\n",
    "df_datas = pd.DataFrame(df_datas_list)\n",
    "\n",
    "print(f\"✅ Sucesso! Geradas {len(df_datas)} linhas de base para o histórico.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "colunas_necessarias = [\"Assessor\", \"Mes\", \"Faixa Cliente Abertura\", \"Faixa Cliente Atual\"]\n",
    "colunas_atuais = df.columns.tolist()\n",
    "\n",
    "missing = [c for c in colunas_necessarias if c not in colunas_atuais]\n",
    "\n",
    "if not missing:\n",
    "    print(\"Todas as colunas necessárias estão presentes!\")\n",
    "else:\n",
    "    print(f\"Erro: Faltam as seguintes colunas: {missing}\")\n",
    "    print(f\"Colunas disponíveis: {colunas_atuais}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Realiza o merge para trazer as contagens de contas\n",
    "df_final = pd.merge(\n",
    "    df_datas, \n",
    "    df[['Mes', 'Assessor', 'Faixa Cliente Abertura', 'Faixa Cliente Atual', 'Contas Abertas', 'Contas Vinculadas']], \n",
    "    on=['Mes', 'Assessor', 'Faixa Cliente Abertura', 'Faixa Cliente Atual'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Preenche os campos vazios com 0\n",
    "df_final.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conexao = Connect.connect_techdb()\n",
    "times = Connect.import_table(conexao, \"times_nova_empresa\")\n",
    "conexao.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datas = df_datas[df_datas['Assessor'].isin(times['Assessor'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_datas, df, on=['Mes', 'Faixa Cliente Abertura', 'Faixa Cliente Atual', 'Assessor'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conexao = Connect.connect_techdb()\n",
    "df.to_sql(\"abertura_de_conta\", \n",
    "          con=conexao, \n",
    "          index=False, \n",
    "          if_exists='replace',\n",
    "          schema='principal')\n",
    "conexao.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contas_abertas = \\\n",
    "    base_filtrada[[\n",
    "        'Data de Abertura', 'Data Vínculo', 'Conta', 'Nome',\n",
    "        'Assessor', 'Tipo', 'PL Abertura', 'PL Atual'\n",
    "    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primeiro_dia_semana = (datetime.today() - timedelta(days = datetime.today().weekday())).strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contas_abertas = contas_abertas[contas_abertas['Data Vínculo'] >= primeiro_dia_semana]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conexao =Connect.connect_techdb()\n",
    "infos_clientes = Connect.import_table(conexao, \"infos_clientes\")\n",
    "conexao.close()\n",
    "infos_clientes.rename(columns={\"Tipo\":\"Tipo de conta\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contas_abertas = contas_abertas.merge(infos_clientes[['Conta', 'Tipo de conta', 'Profissão / Setor', 'IDADE']], on='Conta', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contas_abertas.to_excel(r\"C:\\Scripts\\backups_atria\\diarios\\arquivos_banco\\scripts\\relatorios\\entradas_e_saidas\\contas_novas_semana.xlsx\", header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
