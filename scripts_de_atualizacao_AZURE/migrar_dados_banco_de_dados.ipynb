{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import winsound\n",
    "import ctypes\n",
    "\n",
    "# Adicionando caminhos dos módulos (ajuste se necessário)\n",
    "sys.path.insert(0, r'C:\\Scripts\\modules_azure\\database')\n",
    "sys.path.insert(0, r'C:\\Scripts\\modules_azure\\parameters')\n",
    "\n",
    "# Importando os módulos novos\n",
    "from connection_azure import Connect\n",
    "from azure_loader import AzureLoader\n",
    "from parametros import Parametros\n",
    "\n",
    "\n",
    "SCHEMA_DEFAULT = \"dbo\" \n",
    "CAMINHO_RELATORIOS = Parametros.caminho_completo_atual()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Definição dos parametros</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diretório base: C:\\Scripts\\relatórios\\\\06-02-2026\\0848\\\n"
     ]
    }
   ],
   "source": [
    "if not CAMINHO_RELATORIOS:\n",
    "    print(\"Erro: Pasta de relatórios de hoje não encontrada.\")\n",
    "    sys.exit()\n",
    "\n",
    "print(f\"Diretório base: {CAMINHO_RELATORIOS}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Migração das tabelas</center></h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Tabela times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subindo a tabela de Times\n",
      "[AzureLoader] Subindo tabela: dbo.times_nova_empresa (15 linhas)...\n",
      "[AzureLoader] Chunksize calculado: 696 linhas/lote (Colunas: 3).\n",
      "[AzureLoader] Configurando Primary Key: Assessor\n",
      "[AzureLoader] Concluido: times_nova_empresa atualizada.\n"
     ]
    }
   ],
   "source": [
    "print(\"Subindo a tabela de Times\")\n",
    "try:\n",
    "    times = pl.read_excel(\"C:\\\\Scripts\\\\times_atria.xlsx\")\n",
    "    times = times.with_columns(pl.col(\"Assessor\").str.to_uppercase())\n",
    "    \n",
    "    # Envio com AzureLoader\n",
    "    AzureLoader.enviar_df(\n",
    "        df=times.to_pandas(),\n",
    "        nome_tabela=\"times_nova_empresa\",\n",
    "        col_pk=\"Assessor\",\n",
    "        if_exists=\"replace\",\n",
    "        schema=SCHEMA_DEFAULT\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Erro em Times: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tipo clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificando Tipo de Clientes\n",
      "[AzureLoader] Lendo: dbo.base_btg...\n",
      "[AzureLoader] Lendo: dbo.tipo_clientes...\n",
      "Nenhum cliente novo para classificar.\n"
     ]
    }
   ],
   "source": [
    "print(\"Classificando Tipo de Clientes\")\n",
    "try:\n",
    "    # Lê as tabelas atuais do Azure para comparação\n",
    "    base_btg_db = AzureLoader.ler_tabela(\"base_btg\", schema=SCHEMA_DEFAULT)\n",
    "    tipo_clientes_hist = AzureLoader.ler_tabela(\"tipo_clientes\", schema=SCHEMA_DEFAULT)\n",
    "    \n",
    "    if not base_btg_db.empty:\n",
    "        tipo_clientes = base_btg_db.loc[:, [\"Conta\", \"Tipo\"]]\n",
    "        \n",
    "        # Filtra apenas contas que NÃO estão no histórico\n",
    "        if not tipo_clientes_hist.empty:\n",
    "            tipo_clientes = tipo_clientes[~tipo_clientes['Conta'].isin(tipo_clientes_hist['Conta'])]\n",
    "        \n",
    "        if not tipo_clientes.empty:\n",
    "            tipo_clientes.loc[tipo_clientes['Tipo'].isnull(), \"Tipo\"] = 'Offshore'\n",
    "            \n",
    "            # Append apenas dos novos\n",
    "            AzureLoader.enviar_df(\n",
    "                df=tipo_clientes,\n",
    "                nome_tabela=\"tipo_clientes\",\n",
    "                if_exists=\"append\", # Mantém o histórico, adiciona novos\n",
    "                schema=SCHEMA_DEFAULT\n",
    "                # Nota: Não passamos col_pk aqui pois é append, a tabela já existe\n",
    "            )\n",
    "        else:\n",
    "            print(\"Nenhum cliente novo para classificar.\")\n",
    "    else:\n",
    "        print(\"Tabela base_btg vazia ou inexistente no banco.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro em Tipo Clientes: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base BTG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atualizando Base BTG e Offshore\n",
      "[AzureLoader] Subindo tabela: dbo.pl_offshore (57 linhas)...\n",
      "[AzureLoader] Chunksize calculado: 522 linhas/lote (Colunas: 4).\n",
      "[AzureLoader] Configurando Primary Key: Conta\n",
      "[AzureLoader] Concluido: pl_offshore atualizada.\n",
      "[AzureLoader] Subindo tabela: dbo.base_btg (1244 linhas)...\n",
      "[AzureLoader] Chunksize calculado: 46 linhas/lote (Colunas: 45).\n",
      "[AzureLoader] Configurando Primary Key: Conta\n",
      "[AzureLoader] Concluido: base_btg atualizada.\n"
     ]
    }
   ],
   "source": [
    "print(\"Atualizando Base BTG e Offshore\")\n",
    "try:\n",
    "    # Leitura do Excel do dia\n",
    "    base = pd.read_excel(os.path.join(CAMINHO_RELATORIOS, \"base_btg.xlsx\"), header=2)\n",
    "    base.rename(columns={\"E-Mail Comunicação\": \"E-mail\"}, inplace=True)\n",
    "    \n",
    "    # Limpeza de nomes de colunas (R$)\n",
    "    base.columns = [col.replace(\" (R$)\", \"\") for col in base.columns]\n",
    "    base['Conta'] = base['Conta'].astype(str).str.strip()\n",
    "    \n",
    "    # Tratamentos de texto\n",
    "    base['Assessor'] = base['Assessor'].astype(str).str.upper()\n",
    "    \n",
    "    # Normalização Faixa Cliente\n",
    "    base.loc[base['Faixa Cliente'].isin([\"Ate 50K\", \"Entre 50k e 100k\", \"Entre 100k e 300k\"]), \"Faixa Cliente\"] = \"Até 300k\"\n",
    "    \n",
    "    # Processamento Offshore\n",
    "    offshore = pd.read_excel(r\"C:\\Scripts\\historico_auc\\AuC Offshore.xlsx\", sheet_name='AuC Offshore')\n",
    "    offshore = offshore.loc[:, [\"Nome\", \"Conta\", \"AUC BRL\", \"Assessor\"]]\n",
    "    offshore.rename(columns={\"AUC BRL\": \"PL Total\"}, inplace=True)\n",
    "    offshore['Conta'] = offshore['Conta'].astype(str).str.strip()\n",
    "    offshore['Assessor'] = offshore['Assessor'].astype(str).str.upper()\n",
    "    \n",
    "    # Upload PL Offshore\n",
    "    AzureLoader.enviar_df(\n",
    "        df=offshore,\n",
    "        nome_tabela=\"pl_offshore\",\n",
    "        col_pk=\"Conta\",\n",
    "        if_exists=\"replace\",\n",
    "        schema=SCHEMA_DEFAULT\n",
    "    )\n",
    "    \n",
    "    # Concatenação e Ajustes Finais Base\n",
    "    base_full = pd.concat([offshore, base], axis=0)\n",
    "    \n",
    "    # Ajuste Assessores Reais\n",
    "    base_full.loc[base_full['Assessor'] == \"MURILO LUIZ SILVA GINO\", \"Assessor\"] = \"IZADORA VILLELA FREITAS\"\n",
    "    base_full.loc[base_full['Assessor'].str.contains(\"GABRIEL GUERRERO TORRES FONSECA\", na=False), \"Assessor\"] = \"MARCOS SOARES PEREIRA FILHO\"\n",
    "    \n",
    "    base_full.drop_duplicates(subset=\"Conta\", keep='first', inplace=True)\n",
    "    base_full.rename(columns={\"Perfil de Cliente\": \"Perfil do Cliente\"}, inplace=True)\n",
    "    \n",
    "    # Ajuste Rodrigo\n",
    "    base_full.loc[base_full['Assessor'].isin([\"Rodrigo de Mello D?Elia\", \"Rodrigo de Mello DElia\", \"RODRIGO DE MELLO DELIA\"]), \"Assessor\"] = \"RODRIGO DE MELLO D’ELIA\"\n",
    "    \n",
    "    # Upload Base BTG Completa\n",
    "    AzureLoader.enviar_df(\n",
    "        df=base_full,\n",
    "        nome_tabela=\"base_btg\",\n",
    "        col_pk=\"Conta\",\n",
    "        if_exists=\"replace\",\n",
    "        schema=SCHEMA_DEFAULT\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro em Base BTG/Offshore: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acompanhamento de custódia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro em Custódia: list index out of range\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    arquivos = os.listdir(CAMINHO_RELATORIOS)\n",
    "    arquivo_custodia = [f for f in arquivos if 'acompanhamento-de-custodia' in f][0]\n",
    "    \n",
    "    custodia = pd.read_excel(os.path.join(CAMINHO_RELATORIOS, arquivo_custodia))\n",
    "    \n",
    "    AzureLoader.enviar_df(\n",
    "        df=custodia,\n",
    "        nome_tabela=\"acompanhamento_custodia\",\n",
    "        if_exists=\"replace\",\n",
    "        schema=SCHEMA_DEFAULT\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Erro em Custódia: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nomes completos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AzureLoader] Subindo tabela: dbo.nomes_clientes (2980 linhas)...\n",
      "[AzureLoader] Chunksize calculado: 1000 linhas/lote (Colunas: 2).\n",
      "[AzureLoader] Configurando Primary Key: Conta\n",
      "[AzureLoader] Concluido: nomes_clientes atualizada.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    caminho_nomes = r\"C:\\Scripts\\nomes_clientes\\Nomes_Clientes2.xlsx\"\n",
    "    nomes_clientes = pd.read_excel(caminho_nomes)\n",
    "    nomes_clientes.rename(columns={\"Código\": \"Conta\"}, inplace=True)\n",
    "    nomes_clientes['Conta'] = nomes_clientes['Conta'].astype(str).str.strip()\n",
    "    nomes_clientes = nomes_clientes[~nomes_clientes['Nome'].isna()]\n",
    "    \n",
    "    # Merge com a base recém tratada (usando base_full da memória)\n",
    "    temp_base = base_full[['Conta', 'Nome']].copy()\n",
    "    nomes_clientes = pd.merge(temp_base, nomes_clientes, on=\"Conta\", how='outer', suffixes=('_novo', '_antigo'))\n",
    "    \n",
    "    # Preenchimento de nomes\n",
    "    nomes_clientes['Nome'] = nomes_clientes['Nome_antigo'].fillna(nomes_clientes['Nome_novo'])\n",
    "    nomes_clientes = nomes_clientes[['Conta', 'Nome']] # Mantém apenas colunas finais\n",
    "    \n",
    "    nomes_clientes['Conta'] = nomes_clientes['Conta'].astype(str)\n",
    "    nomes_clientes.drop_duplicates(subset='Conta', inplace=True)\n",
    "    \n",
    "    # Salva Excel e Banco\n",
    "    nomes_clientes.to_excel(caminho_nomes, header=True, index=False)\n",
    "    \n",
    "    AzureLoader.enviar_df(\n",
    "        df=nomes_clientes,\n",
    "        nome_tabela=\"nomes_clientes\",\n",
    "        col_pk=\"Conta\",\n",
    "        if_exists=\"replace\",\n",
    "        schema=SCHEMA_DEFAULT\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Erro em Nomes Clientes: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Saldo CC</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AzureLoader] Subindo tabela: dbo.saldo_conta_corrente (625 linhas)...\n",
      "[AzureLoader] Chunksize calculado: 696 linhas/lote (Colunas: 3).\n",
      "[AzureLoader] Configurando Primary Key: Conta\n",
      "[AzureLoader] Concluido: saldo_conta_corrente atualizada.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    saldo_cc = pd.read_excel(os.path.join(CAMINHO_RELATORIOS, \"saldo_cc.xlsx\"), header=2)\n",
    "    saldo_cc.columns = [col.replace(\" (R$)\", \"\") for col in saldo_cc.columns]\n",
    "    saldo_cc.rename(columns={\"Saldo\": \"SALDO\"}, inplace=True)\n",
    "    \n",
    "    saldo_cc = saldo_cc.loc[:, [\"Conta\", \"SALDO\"]]\n",
    "    saldo_cc['Conta'] = saldo_cc['Conta'].astype(str).str.strip()\n",
    "    \n",
    "    # Merge com base para pegar Assessor\n",
    "    saldo_cc = pd.merge(saldo_cc, base_full[['Assessor', 'Conta']], on='Conta', how='left')\n",
    "    \n",
    "    AzureLoader.enviar_df(\n",
    "        df=saldo_cc,\n",
    "        nome_tabela=\"saldo_conta_corrente\",\n",
    "        col_pk=\"Conta\",\n",
    "        if_exists=\"replace\",\n",
    "        schema=SCHEMA_DEFAULT\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Erro em Saldo CC: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Posição</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AzureLoader] Subindo tabela: dbo.posicao (16643 linhas)...\n",
      "[AzureLoader] Chunksize calculado: 83 linhas/lote (Colunas: 25).\n",
      "[AzureLoader] Concluido: posicao atualizada.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    posicao = pd.read_excel(os.path.join(CAMINHO_RELATORIOS, \"posição.xlsx\"), header=2)\n",
    "    posicao.columns = [col.replace(\" (R$)\", \"\") for col in posicao.columns]\n",
    "    \n",
    "    posicao.rename(columns={'CONTA': 'Conta', 'Submercado': 'Sub Mercado', \"Vencimento\": \"VENCIMENTO\", \"Escritório\": \"ESCRITÓRIO\"}, inplace=True)\n",
    "    posicao['Conta'] = posicao['Conta'].astype(str).str.strip()\n",
    "    posicao['VENCIMENTO'] = pd.to_datetime(posicao['VENCIMENTO'], format=\"%Y-%m-%d\", errors='coerce')\n",
    "    \n",
    "    posicao = pd.merge(posicao, base_full[['Conta', 'Assessor']], on='Conta', how='left')\n",
    "    posicao.rename(columns={\"IR\": \"Soma de IR\", \"IOF\": \"Soma de IOF\"}, inplace=True)\n",
    "    if \"ESCRITÓRIO\" in posicao.columns:\n",
    "        posicao.drop(\"ESCRITÓRIO\", axis=1, inplace=True)\n",
    "    \n",
    "    # Lógica de Setores\n",
    "    setores = pd.read_excel(r\"C:\\Scripts\\setores_ativos\\setores.xlsx\")\n",
    "    posicao['Setor'] = ''\n",
    "    posicao['Subsetor'] = ''\n",
    "    \n",
    "    # Otimização da iteração (usando map em vez de loop lento)\n",
    "    map_setor = dict(zip(setores['Ativo'], setores['SETOR_ECONÔMICO']))\n",
    "    map_subsetor = dict(zip(setores['Ativo'], setores['SUBSETOR']))\n",
    "    # Nota: A lógica original varre emissor também, mantendo loop simplificado ou usando apply\n",
    "    for index, row in setores.iterrows():\n",
    "        mask = (posicao['Ativo'] == row['Ativo']) | (posicao['Emissor'] == row['Emissor'])\n",
    "        posicao.loc[mask, 'Setor'] = row['SETOR_ECONÔMICO']\n",
    "        posicao.loc[mask, 'Subsetor'] = row['SUBSETOR']\n",
    "\n",
    "    AzureLoader.enviar_df(\n",
    "        df=posicao,\n",
    "        nome_tabela=\"posicao\",\n",
    "        if_exists=\"replace\",\n",
    "        schema=SCHEMA_DEFAULT\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Erro em Posição: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Renda fixa</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AzureLoader] Subindo tabela: dbo.renda_variavel (1776 linhas)...\n",
      "[AzureLoader] Chunksize calculado: 116 linhas/lote (Colunas: 18).\n",
      "[AzureLoader] Concluido: renda_variavel atualizada.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    rv = pd.read_excel(os.path.join(CAMINHO_RELATORIOS, \"renda_variavel.xlsx\"), header=2)\n",
    "    rv.columns = [col.replace(\" (R$)\", \"\") for col in rv.columns]\n",
    "    rv.rename(columns={\"Data Vencimento\": \"DATA VENCIMENTO\", \"'DL_D_ContaAssessor'[NR_CONTA]\": \"Conta\"}, inplace=True)\n",
    "    \n",
    "    rv['DATA VENCIMENTO'] = pd.to_datetime(rv['DATA VENCIMENTO'], format=(\"%Y-%m-%d\"), errors='coerce')\n",
    "    rv['Conta'] = rv['Conta'].astype(str).str.strip()\n",
    "    \n",
    "    # Cálculos\n",
    "    rv['Valor Bruto Inicial'] = rv['Preço Médio'] * rv['Quantidade']\n",
    "    rv['Performance'] = ((rv['Valor Bruto'] - rv['Valor Bruto Inicial']) / rv['Valor Bruto Inicial']) * 100\n",
    "    rv.loc[rv['Performance'] == np.inf, \"Performance\"] = 0\n",
    "    \n",
    "    AzureLoader.enviar_df(df=rv, nome_tabela=\"renda_variavel\", if_exists=\"replace\", schema=SCHEMA_DEFAULT)\n",
    "except Exception as e:\n",
    "    print(f\"Erro em Renda Variável: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Renda varíavel</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AzureLoader] Subindo tabela: dbo.renda_variavel (1776 linhas)...\n",
      "[AzureLoader] Chunksize calculado: 116 linhas/lote (Colunas: 18).\n",
      "[AzureLoader] Concluido: renda_variavel atualizada.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    rv = pd.read_excel(os.path.join(CAMINHO_RELATORIOS, \"renda_variavel.xlsx\"), header=2)\n",
    "    rv.columns = [col.replace(\" (R$)\", \"\") for col in rv.columns]\n",
    "    rv.rename(columns={\"Data Vencimento\": \"DATA VENCIMENTO\", \"'DL_D_ContaAssessor'[NR_CONTA]\": \"Conta\"}, inplace=True)\n",
    "    \n",
    "    rv['DATA VENCIMENTO'] = pd.to_datetime(rv['DATA VENCIMENTO'], format=(\"%Y-%m-%d\"), errors='coerce')\n",
    "    rv['Conta'] = rv['Conta'].astype(str).str.strip()\n",
    "    \n",
    "    # Cálculos\n",
    "    rv['Valor Bruto Inicial'] = rv['Preço Médio'] * rv['Quantidade']\n",
    "    rv['Performance'] = ((rv['Valor Bruto'] - rv['Valor Bruto Inicial']) / rv['Valor Bruto Inicial']) * 100\n",
    "    rv.loc[rv['Performance'] == np.inf, \"Performance\"] = 0\n",
    "    \n",
    "    AzureLoader.enviar_df(df=rv, nome_tabela=\"renda_variavel\", if_exists=\"replace\", schema=SCHEMA_DEFAULT)\n",
    "except Exception as e:\n",
    "    print(f\"Erro em Renda Variável: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Rentabilidade</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AzureLoader] Subindo tabela: dbo.rentabilidade (1085 linhas)...\n",
      "[AzureLoader] Chunksize calculado: 261 linhas/lote (Colunas: 8).\n",
      "[AzureLoader] Configurando Primary Key: Conta\n",
      "[AzureLoader] Concluido: rentabilidade atualizada.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    rent = pd.read_excel(os.path.join(CAMINHO_RELATORIOS, \"rentabilidade.xlsx\"), header=2)\n",
    "    rent['Conta'] = rent['Conta'].astype(str).str.strip()\n",
    "    cols_rent = [\"Conta\", \"Data\", 'Profitability mtd', 'Profitability last 12 months accumulated',\n",
    "                 'Profitability last 6 months accumulated', 'Profitability last 3 months accumulated', \n",
    "                 'Profitability ytd', 'Modelo de Rentabilidade']\n",
    "    rent = rent.loc[:, cols_rent]\n",
    "    \n",
    "    AzureLoader.enviar_df(df=rent, nome_tabela=\"rentabilidade\", col_pk=\"Conta\", if_exists=\"replace\", schema=SCHEMA_DEFAULT)\n",
    "except Exception as e:\n",
    "    print(f\"Erro em Rentabilidade: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PL Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AzureLoader] Lendo: dbo.PL Base...\n",
      "[AzureLoader] Lendo: dbo.offshore_adicionar_pl_mes_vigente...\n",
      "[AzureLoader] Subindo tabela: dbo.offshore_adicionar_pl_mes_vigente (535 linhas)...\n",
      "[AzureLoader] Chunksize calculado: 522 linhas/lote (Colunas: 4).\n",
      "[AzureLoader] Concluido: offshore_adicionar_pl_mes_vigente atualizada.\n",
      "[AzureLoader] Subindo tabela: dbo.PL Base (76930 linhas)...\n",
      "[AzureLoader] Chunksize calculado: 522 linhas/lote (Colunas: 4).\n",
      "[AzureLoader] Concluido: PL Base atualizada.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # 1. Carrega Histórico do Banco\n",
    "    pl_base_hist = AzureLoader.ler_tabela(\"PL Base\", schema=SCHEMA_DEFAULT)\n",
    "    \n",
    "    # 2. Prepara Base Atual (usa base_full já carregada na memória no passo 3)\n",
    "    base_hoje = base_full.copy() # Usa a base com offshore já concatenada\n",
    "    base_hoje = base_hoje[['Assessor', 'Conta', 'PL Total']]\n",
    "    base_hoje.rename(columns={'PL Total': 'PL', 'Conta': 'CONTA'}, inplace=True)\n",
    "    base_hoje['Mês'] = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    # 3. Prepara Offshore Histórico (tabela auxiliar de histórico offshore)\n",
    "    pl_offshore_hist = AzureLoader.ler_tabela(\"offshore_adicionar_pl_mes_vigente\", schema=SCHEMA_DEFAULT)\n",
    "    \n",
    "    # 4. Atualiza tabela auxiliar Offshore\n",
    "    offshore_current = offshore.copy() # Do passo 3\n",
    "    offshore_current.rename(columns={\"PL Total\": \"PL\", \"Conta\": \"CONTA\"}, inplace=True)\n",
    "    offshore_current['Mês'] = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "    if \"Nome\" in offshore_current.columns:\n",
    "        offshore_current.drop(\"Nome\", axis=1, inplace=True)\n",
    "        \n",
    "    # Remove mês atual do histórico para não duplicar e adiciona o novo\n",
    "    data_corte_mes = datetime.today().strftime(\"%Y-%m-01\")\n",
    "    \n",
    "    if not pl_offshore_hist.empty:\n",
    "        # Garante formato string YYYY-MM-DD para comparação\n",
    "        # Ajuste dependendo de como o pandas leu do SQL (datetime ou str)\n",
    "        if pd.api.types.is_datetime64_any_dtype(pl_offshore_hist['Mês']):\n",
    "             pl_offshore_hist = pl_offshore_hist[pl_offshore_hist['Mês'] < datetime.today().replace(day=1)]\n",
    "             pl_offshore_hist['Mês'] = pl_offshore_hist['Mês'].dt.strftime(\"%Y-%m-%d\")\n",
    "        else:\n",
    "             pl_offshore_hist = pl_offshore_hist[pl_offshore_hist['Mês'] < data_corte_mes]\n",
    "\n",
    "    offshore_atualizado = pd.concat([offshore_current, pl_offshore_hist], axis=0)\n",
    "    \n",
    "    AzureLoader.enviar_df(\n",
    "        df=offshore_atualizado, \n",
    "        nome_tabela=\"offshore_adicionar_pl_mes_vigente\", \n",
    "        if_exists=\"replace\", \n",
    "        schema=SCHEMA_DEFAULT\n",
    "    )\n",
    "    \n",
    "    # 5. Consolidação Final do PL Base\n",
    "    # Filtra histórico removendo mês atual\n",
    "    if not pl_base_hist.empty:\n",
    "         if pd.api.types.is_datetime64_any_dtype(pl_base_hist['Mês']):\n",
    "             pl_base_hist = pl_base_hist[pl_base_hist['Mês'] < datetime.today().replace(day=1)]\n",
    "         else:\n",
    "             pl_base_hist = pl_base_hist[pl_base_hist['Mês'] < data_corte_mes]\n",
    "    \n",
    "    pl_mes_vigente = pd.concat([pl_base_hist, base_hoje], axis=0)\n",
    "    \n",
    "    # Ajustes finais de nomes no histórico consolidado\n",
    "    replacements = {\n",
    "        \"Murilo Luiz Silva Gino\": \"Fernando Domingues da Silva\",\n",
    "        \"RODRIGO DE MELLO DELIA\": \"RODRIGO DE MELLO D’ELIA\",\n",
    "        \"ROSANA PAVANI\": \"ROSANA APARECIDA PAVANI DA SILVA\",\n",
    "        \"FERNANDO DOMINGUES\": \"FERNANDO DOMINGUES DA SILVA\"\n",
    "    }\n",
    "    pl_mes_vigente['Assessor'] = pl_mes_vigente['Assessor'].replace(replacements)\n",
    "    pl_mes_vigente['Assessor'] = pl_mes_vigente['Assessor'].astype(str).str.upper()\n",
    "    pl_mes_vigente['PL'] = pl_mes_vigente['PL'].fillna(0)\n",
    "    pl_mes_vigente['CONTA'] = pl_mes_vigente['CONTA'].astype(str)\n",
    "    \n",
    "    # Converte coluna Mês para datetime para padronizar no SQL\n",
    "    pl_mes_vigente['Mês'] = pd.to_datetime(pl_mes_vigente['Mês'])\n",
    "    \n",
    "    pl_mes_vigente.drop_duplicates(subset=[\"CONTA\", \"Mês\"], keep='first', inplace=True)\n",
    "    \n",
    "    AzureLoader.enviar_df(\n",
    "        df=pl_mes_vigente,\n",
    "        nome_tabela=\"PL Base\",\n",
    "        if_exists=\"replace\",\n",
    "        schema=SCHEMA_DEFAULT\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro em PL Base: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Atualizando Horário de Execução ---\n",
      "[AzureLoader] Subindo tabela: dbo.horario_atualizacao_relatorios (1 linhas)...\n",
      "[AzureLoader] Chunksize calculado: 1000 linhas/lote (Colunas: 1).\n",
      "[AzureLoader] Concluido: horario_atualizacao_relatorios atualizada.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Atualizando Horário de Execução ---\")\n",
    "horario_atualizacao = pd.DataFrame([datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")], columns=[\"Horario\"])\n",
    "AzureLoader.enviar_df(df=horario_atualizacao, nome_tabela=\"horario_atualizacao_relatorios\", if_exists=\"replace\", schema=SCHEMA_DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempo_fim = datetime.now().strftime('%H:%M:%S')\n",
    "ctypes.windll.user32.MessageBoxW(0, f\"O pipeline de dados foi concluído com sucesso às {tempo_fim}.\", \"ETL Finalizado\", 0x40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
